{
  "title": "John Boen - Projects Hub",
  "groups": [
    {
      "id": "home",
      "name": "Home",
           "url": "./sites/home/",
      "sites": [
        {
          "id": "home-page",
          "label": "Welcome & Updates",
          "description": "Project hub overview and recent updates.",
          "url": "./sites/home/",
          "embed": true
        }
      ]
    },
    {
      "id": "software-engineering",
      "name": "Software Engineering",
      "url": "./sites/software-engineering/",
      "sites": [
        {
          "id": "database-engineering",
          "label": "Database Engineering",
          "description": {
            "what_it_is": "The discipline that determines how data is modeled, stored, indexed, and retrieved. It covers schema design, query tuning, indexing, high-reliability architectures, and operational troubleshooting.",
            "why_it_is_valuable": "Every application depends on a stable, correct, and fast source of truth. Good database engineering reduces latency, simplifies analytics, improves correctness, and prevents outages. Strong foundations at this layer reduce costs and make the entire stack more predictable.",
            "my_experience": "I began my career as a database engineer and have designed schemas for high-traffic systems, optimized slow queries, solved locking and deadlocking problems, managed migrations, and maintained systems requiring high reliability. This experience underpins every other data role I take on."
          },
          "url": "./sites/database-engineering/",
          "embed": true
        },
        {
          "id": "data-engineering",
          "label": "Data Engineering",
          "description": {
            "what_it_is": "Data engineering is the creation of pipelines that ingest, transform, and deliver data through ETL/ELT systems, batch and streaming workflows, and layered data models (raw → curated → analytics/AI-ready).",
            "why_it_is_valuable": "Raw data is often incomplete, inconsistent, or trapped in isolated systems. Data engineering solves this by creating dependable pipelines and curated layers so analysts, ML systems, and AI agents can trust the data they consume.",
            "my_experience": "I have built end-to-end ETL/ELT pipelines, operational data flows, migrations, lineage maps, and data integration systems across multiple industries. My work emphasizes reliability, validation, and creating systems that can be easily extended or audited."
          },
          "url": "./sites/data-engineering/",
          "embed": true
        },
        {
          "id": "data-science-ml",
          "label": "Data Science/ML",
          "description": {
            "what_it_is": "Data science and machine learning involve extracting insights from data through statistical analysis, predictive modeling, and training algorithms to recognize patterns, make predictions, and automate decision-making. This includes feature engineering, model training, evaluation, deployment, and monitoring.",
            "why_it_is_valuable": "Data science transforms historical data into actionable predictions and insights. ML models can automate complex decisions, detect anomalies, personalize experiences, and uncover patterns humans might miss. Together they enable organizations to move from reactive to predictive operations.",
            "my_experience": "I have built predictive models, classification systems, recommendation engines, and anomaly detection pipelines. My background in data engineering and quality ensures that ML systems are built on clean, reliable data. I focus on models that are explainable, maintainable, and operationally sound—not just accurate in notebooks."
          },
          "url": "./sites/data-science-ml/",
          "embed": true
        },
        {
          "id": "data-management",
          "label": "Data Management",
          "description": {
            "what_it_is": "Data management governs how data is accessed, secured, retained, and controlled across its entire lifecycle. It includes compliance, auditability, access control, security boundaries, retention schedules, archival, and deletion.",
            "why_it_is_valuable": "Data is powerful—and dangerous if mishandled. Regulations such as HIPAA, GLBA, COPPA, and GDPR mean that organizations must treat data as a regulated asset. Governance prevents breaches, fines, and misuse while increasing trust in the organization.",
            "my_experience": "I've built systems that comply with HIPAA, GLBA, COPPA, GDPR, and similar frameworks. I've handled retention, archival, deletion, legal holds, privacy boundaries, and role-based access systems. I design systems that remain legally safe and operationally efficient."
          },
          "url": "./sites/data-management/",
          "embed": true
        },
        {
          "id": "ai-engineering-journey",
          "label": "AI Engineering Journey",
          "description": {
            "what_it_is": "Agentic AI engineering focuses on building systems where large language models coordinate tools, reason over data, and complete tasks end-to-end. This includes RAG pipelines, tool-calling, workflow orchestration, evaluation loops, and building AI that behaves like a collaborator rather than a passive model.",
            "why_it_is_valuable": "Organizations don't need chatbots—they need AI that acts responsibly on their data, respects permissions, calls APIs, summarizes documents, and automates repetitive workflows. Agentic architectures create an ‘intelligent glue layer' across existing systems, improving speed, consistency, and decision-making.",
            "my_experience": "I bring decades of database, data engineering, data governance, and operational experience from Boeing, Microsoft, Getty Images, Demand Media, Virtuoso, and Google. I design RAG systems, agent workflows, vector retrieval layers, and pipelines that guarantee traceability and correctness. My background ensures AI systems are grounded in real data, not guesswork."
          },
          "url": "./sites/ai-agentic/",
          "embed": true,
          "default": true
        },
        {
          "id": "data-quality",
          "label": "Data Quality",
          "description": {
            "what_it_is": "Data quality ensures that data is accurate, complete, consistent, and reliable. It includes validation, deduplication, anomaly detection, reconciliation across systems, and monitoring.",
            "why_it_is_valuable": "Downstream systems—including analytics, operations, and AI—are only as good as their inputs. Poor data quality leads to incorrect insights, faulty decisions, and unreliable automation.",
            "my_experience": "Throughout my career I have diagnosed and repaired bad pipelines, schema mismatches, off-by-one logic, timezone issues, broken joins, and source-of-truth conflicts. I design monitoring systems that detect issues early and guarantee trustworthiness."
          },
          "url": "./sites/data-quality/",
          "embed": true
        },
        {
          "id": "data-presentation",
          "label": "Data Presentation",
          "description": {
            "what_it_is": "The practice of transforming complex data into dashboards, visualizations, summaries, and narratives that help people make decisions.",
            "why_it_is_valuable": "Good presentation bridges the gap between raw facts and understanding. It guides decision-makers, reduces confusion, and ensures the right people see the right insights at the right time.",
            "my_experience": "I've created dashboards, operational reports, and executive-level narratives that distill complex datasets into actionable insights. I focus on clarity, accuracy, and respecting the audience's needs—whether technical or non-technical."
          },
          "url": "./sites/data-presentation/",
          "embed": true
        }
      ],
      "how_it_fits_together": "All of these roles—database engineering, data engineering, data science/ML, data management, data presentation, and data quality—form a unified discipline: making data trustworthy, understandable, and usable. Everything I do in AI engineering builds on these foundations. My career has been the long arc of designing, moving, securing, validating, explaining, and predicting from data, and now applying that knowledge to create agentic AI systems that act responsibly over that data."
    },
    {
      "id": "martial-arts-fitness",
      "name": "Martial Arts & Fitness",
      "url": "./sites/martial-arts-fitness/",
      "sites": [
        {
          "id": "solo-martial-artist",
          "label": "Solo Martial Artist",
          "description": "Solo drills, training logs, and progression systems for martial artists training alone.",
          "url": "./sites/martial-arts/",
          "embed": true
        }
      ]
    },
    {
      "id": "making-anything",
      "name": "Making Anything",
      "url": "./sites/making-anything-group/",
      "sites": [
        {
          "id": "maker-projects",
          "label": "Maker Projects",
          "description": "Hands-on builds involving electronics, fabrication, prototyping, and creative engineering across DIY disciplines.",
          "url": "./sites/making-anything/",
          "embed": true
        }
      ]
    }
  ]
}
